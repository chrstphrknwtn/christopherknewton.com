export default {
  slug: 'computer-interfaces',
  date: '11 September 2020',
  title: 'Computer interfaces',
  description: `The idea that designers and engineers create _user interfaces_ is one of truly stunning hubris. _Human-computer interface_ is little more palatable if only because it accurately describes the two things that are _interfacing_.

When we create what is commonly referred to as a _user interface_, whether audio, graphical or textual, we are really creating a _computer interface_. A _human-computer interface_ is the point at which both human and computer meet in an overall system. The exact point of interface is blurry and necessarily comprises part of both human and computer. However as designers and engineers we are only able to shape and implement the computer part.

We can inspect the brain via fMRI to see what parts light up as various senses are stimulated, but the underlying physiological systems are essentially off-limits, they are what they are and we without a deep understanding how they function. We know where bits and pieces are, how our senses function biologically, chemically and physically. We can map how the parts are wired together, but this is not much better than being able to point out which cables plug into which port on the back of your computer.

This article is merely a rant on the ridiculousness of the term, rather than a reframing of any problem or practice. I'm simply suggesting that if we said _computer interfaces_, maybe we'd actually think about the human part a bit more. Counter-intuitive perhaps, but not necessarily against our better intuition. When designing a computer system and its interface, questions like "how to we get the user to click here" and "we need to make the user do X" are par for the course. Rarely do we ask "how can we get the computer to be there" or "when a human does X, what should the computer being doing?" I'm now imagining people yelling "it's called user-entered design!", which essentially says start with the user and works backwards. But we're still working backwards toward the computer and deciding how the computer should be; we're still imagining what the computer will be like, not the human.

Let's take something like the smartphone. It's a small computer that billions of people take with them everywhere. It's a great piece of product design... it puts the device where it is most useful for the human. The iPhone isn't _user design_, it's the physical result of thinking "what could a computer product be like?"

Framing the problem as _user interface_ design puts the user in the active role, a human must reach out and touch a computer. A human initiates and completes tasks. An interesting example of this is compilers. I've written a little bit of C, some personal command line tools and messing around with microcontrollers. Clang and GCC are pretty amazing in that they can tell you where issues in your code are, which always begs the question _if the computer already knows the problem, why doesn't it just fix it?_  It's a ridiculous reversal of roles, I've sat down to get a computer to do something for me, and now it's giving me commands? Compiler errors and warnings one part of their interface, the other being invocation arguments. This perverse reversal puts the onus on the human to figure out the computer, to understand the internal symbols and systems of the box in front of them, whilst completing a task that has basically nothing to do with how a computer works. Writing on a computer is a more generally familiar example. Any moment a human wonders how their keyboard or word processor works or wondering where to find a formatting sub-menu is invariably a moment wasted, a moment better spent considering what comes next on the page.`,
  nodes: [],
  links: []
};
